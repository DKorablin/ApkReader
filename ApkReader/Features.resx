<?xml version="1.0" encoding="utf-8"?>
<root>
  <!-- 
    Microsoft ResX Schema 
    
    Version 2.0
    
    The primary goals of this format is to allow a simple XML format 
    that is mostly human readable. The generation and parsing of the 
    various data types are done through the TypeConverter classes 
    associated with the data types.
    
    Example:
    
    ... ado.net/XML headers & schema ...
    <resheader name="resmimetype">text/microsoft-resx</resheader>
    <resheader name="version">2.0</resheader>
    <resheader name="reader">System.Resources.ResXResourceReader, System.Windows.Forms, ...</resheader>
    <resheader name="writer">System.Resources.ResXResourceWriter, System.Windows.Forms, ...</resheader>
    <data name="Name1"><value>this is my long string</value><comment>this is a comment</comment></data>
    <data name="Color1" type="System.Drawing.Color, System.Drawing">Blue</data>
    <data name="Bitmap1" mimetype="application/x-microsoft.net.object.binary.base64">
        <value>[base64 mime encoded serialized .NET Framework object]</value>
    </data>
    <data name="Icon1" type="System.Drawing.Icon, System.Drawing" mimetype="application/x-microsoft.net.object.bytearray.base64">
        <value>[base64 mime encoded string representing a byte array form of the .NET Framework object]</value>
        <comment>This is a comment</comment>
    </data>
                
    There are any number of "resheader" rows that contain simple 
    name/value pairs.
    
    Each data row contains a name, and value. The row also contains a 
    type or mimetype. Type corresponds to a .NET class that support 
    text/value conversion through the TypeConverter architecture. 
    Classes that don't support this are serialized and stored with the 
    mimetype set.
    
    The mimetype is used for serialized objects, and tells the 
    ResXResourceReader how to depersist the object. This is currently not 
    extensible. For a given mimetype the value must be set accordingly:
    
    Note - application/x-microsoft.net.object.binary.base64 is the format 
    that the ResXResourceWriter will generate, however the reader can 
    read any of the formats listed below.
    
    mimetype: application/x-microsoft.net.object.binary.base64
    value   : The object must be serialized with 
            : System.Runtime.Serialization.Formatters.Binary.BinaryFormatter
            : and then encoded with base64 encoding.
    
    mimetype: application/x-microsoft.net.object.soap.base64
    value   : The object must be serialized with 
            : System.Runtime.Serialization.Formatters.Soap.SoapFormatter
            : and then encoded with base64 encoding.

    mimetype: application/x-microsoft.net.object.bytearray.base64
    value   : The object must be serialized into a byte array 
            : using a System.ComponentModel.TypeConverter
            : and then encoded with base64 encoding.
    -->
  <xsd:schema id="root" xmlns="" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:msdata="urn:schemas-microsoft-com:xml-msdata">
    <xsd:import namespace="http://www.w3.org/XML/1998/namespace" />
    <xsd:element name="root" msdata:IsDataSet="true">
      <xsd:complexType>
        <xsd:choice maxOccurs="unbounded">
          <xsd:element name="metadata">
            <xsd:complexType>
              <xsd:sequence>
                <xsd:element name="value" type="xsd:string" minOccurs="0" />
              </xsd:sequence>
              <xsd:attribute name="name" use="required" type="xsd:string" />
              <xsd:attribute name="type" type="xsd:string" />
              <xsd:attribute name="mimetype" type="xsd:string" />
              <xsd:attribute ref="xml:space" />
            </xsd:complexType>
          </xsd:element>
          <xsd:element name="assembly">
            <xsd:complexType>
              <xsd:attribute name="alias" type="xsd:string" />
              <xsd:attribute name="name" type="xsd:string" />
            </xsd:complexType>
          </xsd:element>
          <xsd:element name="data">
            <xsd:complexType>
              <xsd:sequence>
                <xsd:element name="value" type="xsd:string" minOccurs="0" msdata:Ordinal="1" />
                <xsd:element name="comment" type="xsd:string" minOccurs="0" msdata:Ordinal="2" />
              </xsd:sequence>
              <xsd:attribute name="name" type="xsd:string" use="required" msdata:Ordinal="1" />
              <xsd:attribute name="type" type="xsd:string" msdata:Ordinal="3" />
              <xsd:attribute name="mimetype" type="xsd:string" msdata:Ordinal="4" />
              <xsd:attribute ref="xml:space" />
            </xsd:complexType>
          </xsd:element>
          <xsd:element name="resheader">
            <xsd:complexType>
              <xsd:sequence>
                <xsd:element name="value" type="xsd:string" minOccurs="0" msdata:Ordinal="1" />
              </xsd:sequence>
              <xsd:attribute name="name" type="xsd:string" use="required" />
            </xsd:complexType>
          </xsd:element>
        </xsd:choice>
      </xsd:complexType>
    </xsd:element>
  </xsd:schema>
  <resheader name="resmimetype">
    <value>text/microsoft-resx</value>
  </resheader>
  <resheader name="version">
    <value>2.0</value>
  </resheader>
  <resheader name="reader">
    <value>System.Resources.ResXResourceReader, System.Windows.Forms, Version=2.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089</value>
  </resheader>
  <resheader name="writer">
    <value>System.Resources.ResXResourceWriter, System.Windows.Forms, Version=2.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089</value>
  </resheader>
  <data name="android.hardware.audio.low_latency" xml:space="preserve">
    <value>The app uses the device's low-latency audio pipeline, which reduces lag and delays when processing sound input or output.</value>
  </data>
  <data name="android.hardware.audio.output" xml:space="preserve">
    <value>The app transmits sound using the device's speakers, audio jack, Bluetooth streaming capabilities, or a similar mechanism.</value>
  </data>
  <data name="android.hardware.audio.pro" xml:space="preserve">
    <value>The app uses the device's high-end audio functionality and performance capabilities.</value>
  </data>
  <data name="android.hardware.bluetooth" xml:space="preserve">
    <value>The app uses the device's Bluetooth features, usually to communicate with other Bluetooth-enabled devices.</value>
  </data>
  <data name="android.hardware.bluetooth_le" xml:space="preserve">
    <value>The app uses the device's Bluetooth Low Energy radio features.</value>
  </data>
  <data name="android.hardware.camera" xml:space="preserve">
    <value>The app uses the device's back-facing camera. Devices with only a front-facing camera do not list this feature, so use the android.hardware.camera.any feature instead if your app can communicate with any camera, regardless of which direction the camera faces.</value>
  </data>
  <data name="android.hardware.camera.any" xml:space="preserve">
    <value>The app uses one of the device's cameras, or an external camera that the user connects to the device. Use this value instead of android.hardware.camera if your app does not require the camera to be a back-facing one.</value>
  </data>
  <data name="android.hardware.camera.autofocus" xml:space="preserve">
    <value>The app uses the autofocus feature that the device's camera supports.</value>
  </data>
  <data name="android.hardware.camera.capability.manual_post_processing" xml:space="preserve">
    <value>The app uses the MANUAL_POST_PROCESSING feature that the device's camera supports.</value>
  </data>
  <data name="android.hardware.camera.capability.manual_sensor" xml:space="preserve">
    <value>The app uses the MANUAL_SENSOR feature that the device's camera supports.</value>
  </data>
  <data name="android.hardware.camera.capability.raw" xml:space="preserve">
    <value>The app uses the RAW feature that the device's camera supports.

    This feature implies that the device can save DNG (raw) files and that the device's camera provides the DNG-related metadata necessary for your app to process these raw images directly.</value>
  </data>
  <data name="android.hardware.camera.external" xml:space="preserve">
    <value>The app communicates with an external camera that the user connects to the device. This feature does not guarantee, however, that the external camera is available for your app to use.</value>
  </data>
  <data name="android.hardware.camera.flash" xml:space="preserve">
    <value>The app uses the flash feature that the device's camera supports.

    By using this feature, an app implies that it also uses the android.hardware.camera feature, unless this parent feature is declared with android:required="false".</value>
  </data>
  <data name="android.hardware.camera.front" xml:space="preserve">
    <value>The app uses the device's front-facing camera.

    By using this feature, an app implies that it also uses the android.hardware.camera feature, unless this parent feature is declared with android:required="false".</value>
  </data>
  <data name="android.hardware.camera.level.full" xml:space="preserve">
    <value>The app uses the FULL-level image-capturing support that at least one of the device's cameras provides. Cameras with FULL support provide burst-capture capabilities, per-frame control, and manual post-processing control.</value>
  </data>
  <data name="android.hardware.consumerir" xml:space="preserve">
    <value>The app uses the device's infrared (IR) capabilities, usually to communicate with other consumer IR devices.</value>
  </data>
  <data name="android.hardware.faketouch" xml:space="preserve">
    <value>The app uses basic touch interaction events, such as tapping and dragging.

When declared as required, this feature indicates that the app is compatible with a device only if that device emulates a touchscreen ("fake touch" interface) or has an actual touchscreen.

A device that offers a fake touch interface provides a user input system that emulates a subset of a touchscreen's capabilities. For example, a mouse or remote control could drive an on-screen cursor. If your app requires basic point and click interaction (in other words, it won't work with only a d-pad controller), you should declare this feature. Because this is the minimum level of touch interaction, you can also use an app that declares this feature on devices that offer more complex touch interfaces.</value>
  </data>
  <data name="android.hardware.faketouch.multitouch.distinct" xml:space="preserve">
    <value>The app tracks two or more distinct "fingers" on a fake touch interface. This is a superset of the android.hardware.faketouch feature. When declared as required, this feature indicates that the app is compatible with a device only if that device emulates distinct tracking of two or more fingers or has an actual touchscreen.

    Unlike the distinct multitouch defined by android.hardware.touchscreen.multitouch.distinct, input devices that support distinct multitouch with a fake touch interface don't support all two-finger gestures because the input in transformed to cursor movement on the screen. That is, single-finger gestures on such a device move a cursor, two-finger swipes cause single-finger touch events to occur, and other two-finger gestures trigger the corresponding two-finger touch events.

    A device that provides a two-finger touch trackpad for cursor movement can support this feature.</value>
  </data>
  <data name="android.hardware.faketouch.multitouch.jazzhand" xml:space="preserve">
    <value>The app tracks five or more distinct "fingers" on a fake touch interface. This is a superset of the android.hardware.faketouch feature. When declared as required, this feature indicates that the app is compatible with a device only if that device emulates distinct tracking of five or more fingers or has an actual touchscreen.

    Unlike the distinct multitouch defined by android.hardware.touchscreen.multitouch.jazzhand, input devices that support jazzhand multitouch with a fake touch interface don't support all five-finger gestures because the input in transformed to cursor movement on the screen. That is, single-finger gestures on such a device move a cursor, multi-finger gestures cause single-finger touch events to occur, and other multi-finger gestures trigger the corresponding multi-finger touch events.

    A device that provides a five-finger touch trackpad for cursor movement can support this feature.</value>
  </data>
  <data name="android.hardware.fingerprint" xml:space="preserve">
    <value>The app reads fingerprints using the device's biometric hardware.</value>
  </data>
  <data name="android.hardware.gamepad" xml:space="preserve">
    <value>The app captures game controller input, either from the device itself or from a connected gamepad.</value>
  </data>
  <data name="android.hardware.location" xml:space="preserve">
    <value>The app uses one or more features on the device for determining location, such as GPS location, network location, or cell location.</value>
  </data>
  <data name="android.hardware.location.gps" xml:space="preserve">
    <value>The app uses precise location coordinates obtained from a Global Positioning System (GPS) receiver on the device.

    By using this feature, an app implies that it also uses the android.hardware.location feature, unless this parent feature is declared with the attribute android:required="false".</value>
  </data>
  <data name="android.hardware.location.network" xml:space="preserve">
    <value>The app uses coarse location coordinates obtained from a network-based geolocation system supported on the device.

    By using this feature, an app implies that it also uses the android.hardware.location feature, unless this parent feature is declared with the attribute android:required="false".</value>
  </data>
  <data name="android.hardware.microphone" xml:space="preserve">
    <value>The app records audio using the device's microphone.</value>
  </data>
  <data name="android.hardware.nfc" xml:space="preserve">
    <value>The app uses the device's Near-Field Communication (NFC) radio features.</value>
  </data>
  <data name="android.hardware.nfc.hce" xml:space="preserve">
    <value>The app uses NFC card emulation that is hosted on the device.</value>
  </data>
  <data name="android.hardware.opengles.aep" xml:space="preserve">
    <value>The app uses the OpenGL ES Android Extension Packthat is installed on the device.</value>
  </data>
  <data name="android.hardware.screen.landscape" xml:space="preserve">
    <value>The app requires the device to use the portrait or landscape orientation. If your app supports both orientations, then you don't need to declare either feature.</value>
  </data>
  <data name="android.hardware.screen.portrait" xml:space="preserve">
    <value>The app requires the device to use the portrait or landscape orientation. If your app supports both orientations, then you don't need to declare either feature.</value>
  </data>
  <data name="android.hardware.sensor.accelerometer" xml:space="preserve">
    <value>The app uses motion readings from the device's accelerometer to detect the device's current orientation. For example, an app could use accelerometer readings to determine when to switch between portrait and landscape orientations.</value>
  </data>
  <data name="android.hardware.sensor.ambient_temperature" xml:space="preserve">
    <value>The app uses the device's ambient (environmental) temperature sensor. For example, a weather app could report indoor or outdoor temperature.</value>
  </data>
  <data name="android.hardware.sensor.barometer" xml:space="preserve">
    <value>The app uses the device's barometer. For example, a weather app could report air pressure.</value>
  </data>
  <data name="android.hardware.sensor.compass" xml:space="preserve">
    <value>The app uses the device's magnetometer (compass). For example, a navigation app could show the current direction a user faces.</value>
  </data>
  <data name="android.hardware.sensor.gyroscope" xml:space="preserve">
    <value>The app uses the device's gyroscope to detect rotation and twist, creating a six-axis orientation system. By using this sensor, an app can detect more smoothly whether it needs to switch between portrait and landscape orientations.</value>
  </data>
  <data name="android.hardware.sensor.heartrate" xml:space="preserve">
    <value>The app uses the device's heart rate monitor. For example, a fitness app could report trends in a user's heart rate over time.</value>
  </data>
  <data name="android.hardware.sensor.heartrate.ecg" xml:space="preserve">
    <value>The app uses the device's elcardiogram (ECG) heart rate sensor. For example, a fitness app could report more detailed information about a user's heart rate.</value>
  </data>
  <data name="android.hardware.sensor.hifi_sensors" xml:space="preserve">
    <value>The app uses the device's high fidelity (Hi-Fi) sensors. For example, a gaming app could detect the user's high-precision movements.</value>
  </data>
  <data name="android.hardware.sensor.light" xml:space="preserve">
    <value>The app uses the device's light sensor. For example, an app could display one of two different color schemes based on the ambient lighting conditions.</value>
  </data>
  <data name="android.hardware.sensor.proximity" xml:space="preserve">
    <value>The app uses the device's proximity sensor. For example, a telephony app could turn off the device's screen when the app detects that the user is holding the device close to their body.</value>
  </data>
  <data name="android.hardware.sensor.relative_humidity" xml:space="preserve">
    <value>The app uses the device's relative humidity sensor. For example, a weather app could use the humidity to calculate and report the current dewpoint.</value>
  </data>
  <data name="android.hardware.sensor.stepcounter" xml:space="preserve">
    <value>The app uses the device's step counter. For example, a fitness app could report the number of steps a user needs to take to achieve their daily step count goal.</value>
  </data>
  <data name="android.hardware.sensor.stepdetector" xml:space="preserve">
    <value>The app uses the device's step detector. For example, a fitness app could use the time interval between steps to infer the type of exercise that the user is doing.</value>
  </data>
  <data name="android.hardware.telephony" xml:space="preserve">
    <value>The app uses the device's telephony features, such as telephony radio with data communication services.</value>
  </data>
  <data name="android.hardware.telephony.cdma" xml:space="preserve">
    <value>The app uses the Code Division Multiple Access (CDMA) telephony radio system.

    By using this feature, an app implies that it also uses the android.hardware.telephony feature, unless this parent feature is declared with android:required="false".</value>
  </data>
  <data name="android.hardware.telephony.gsm" xml:space="preserve">
    <value>The app uses the Global System for Mobile Communications (GSM) telephony radio system.

    By using this feature, an app implies that it also uses the android.hardware.telephony feature, unless this parent feature is declared with android:required="false".</value>
  </data>
  <data name="android.hardware.touchscreen" xml:space="preserve">
    <value>The app uses the device's touchscreen capabilities for gestures that are more interactive than basic touch events, such as a fling. This is a superset of the android.hardware.faketouch feature.

    By default, your app requires this feature. As such, your app is not available to devices that provide only an emulated touch interface ("fake touch") by default. If you want to make your app available on devices that provide a fake touch interface (or even on devices that provide only a d-pad controller), you must explicitly declare that a touchscreen is not required by declaring android.hardware.touchscreen with android:required="false". You should add this declaration if your app uses—but does not require—a real touchscreen interface. All apps that don't explicitly require android.hardware.touchscreen will also work on devices with android.hardware.faketouch.

    If your app in fact requires a touch interface (to perform more advanced touch gestures such as fling), then you don't need to declare any touch interface features because they're required by default. However, it's best if you explicitly declare all features that your app uses.

    If you require more complex touch interaction, such as multi-finger gestures, you should declare that your app uses advanced touchscreen features.</value>
  </data>
  <data name="android.hardware.touchscreen.multitouch" xml:space="preserve">
    <value>The app uses the device's basic two-point multitouch capabilities, such as for pinch gestures, but the app does not need to track touches independently. This is a superset of the android.hardware.touchscreen feature.

    By using this feature, an app implies that it also uses the android.hardware.touchscreen feature, unless this parent feature is declared with android:required="false".</value>
  </data>
  <data name="android.hardware.touchscreen.multitouch.distinct" xml:space="preserve">
    <value>The app uses the device's advanced multitouch capabilities for tracking two or more points independently. This feature is a superset of the android.hardware.touchscreen.multitouch feature.

    By using this feature, an app implies that it also uses the android.hardware.touchscreen.multitouch feature, unless this parent feature is declared with android:required="false".</value>
  </data>
  <data name="android.hardware.touchscreen.multitouch.jazzhand" xml:space="preserve">
    <value>The app uses the device's advanced multitouch capabilities for tracking five or more points independently. This feature is a superset of the android.hardware.touchscreen.multitouch feature.

    By using this feature, an app implies that it also uses the android.hardware.touchscreen.multitouch feature, unless this parent feature is declared with android:required="false".</value>
  </data>
  <data name="android.hardware.type.automotive" xml:space="preserve">
    <value>The app is designed to show its UI on a set of screens inside a vehicle. The user interacts with the app using hard buttons, touch, rotary controllers, and mouse-like interfaces. The vehicle's screens usually appear in the center console or the instrument cluster of a vehicle. These screens usually have limited size and resolution.</value>
  </data>
  <data name="android.hardware.type.television" xml:space="preserve">
    <value>(Deprecated; use android.software.leanback instead.)

    The app is designed to show its UI on a television. This feature defines "television" to be a typical living room television experience: displayed on a big screen, where the user is sitting far away and the dominant form of input is something like a d-pad, and generally not using a mouse, pointer, or touch device.</value>
  </data>
  <data name="android.hardware.type.watch" xml:space="preserve">
    <value>The app is designed to show its UI on a watch. A watch is worn on the body, such as on the wrist. The user is very close to the device while interacting with it.</value>
  </data>
  <data name="android.hardware.usb.accessory" xml:space="preserve">
    <value>The app behaves as the USB device and connects to USB hosts.</value>
  </data>
  <data name="android.hardware.usb.host" xml:space="preserve">
    <value>The app uses the USB accessories that are connected to the device. The device serves as the USB host.</value>
  </data>
  <data name="android.hardware.vulkan.compute" xml:space="preserve">
    <value>The app uses Vulkan compute features. This feature indicates that the app requires the hardware accelerated Vulkan implementation. The feature version indicates which level of optional compute features the app requires beyond the Vulkan 1.0 requirements.</value>
  </data>
  <data name="android.hardware.vulkan.level" xml:space="preserve">
    <value>The app uses Vulkan level features. This feature indicates that the app requires the hardware accelerated Vulkan implementation. The feature version indicates which level of optional hardware features the app requires.</value>
  </data>
  <data name="android.hardware.vulkan.version" xml:space="preserve">
    <value>The app uses Vulkan. This feature indicates that the app requires the hardware accelerated Vulkan implementation. The feature version indicates the minimum version of Vulkan API support the app requires.</value>
  </data>
  <data name="android.hardware.wifi" xml:space="preserve">
    <value>The app uses 802.11 networking (Wi-Fi) features on the device.</value>
  </data>
  <data name="android.hardware.wifi.direct" xml:space="preserve">
    <value>The app uses the Wi-Fi Direct networking features on the device.</value>
  </data>
  <data name="android.software.app_widgets" xml:space="preserve">
    <value>The app uses or provides App Widgets and should be installed only on devices that include a Home screen or similar location where users can embed App Widgets.</value>
  </data>
  <data name="android.software.backup" xml:space="preserve">
    <value>The app includes logic to handle a backup and restore operation.</value>
  </data>
  <data name="android.software.device_admin" xml:space="preserve">
    <value>The app uses device administrators to enforce a device policy.</value>
  </data>
  <data name="android.software.home_screen" xml:space="preserve">
    <value>The app behaves as a replacement to the device's Home screen.</value>
  </data>
  <data name="android.software.input_methods" xml:space="preserve">
    <value>The app uses a new input method, which the developer defines in an InputMethodService.</value>
  </data>
  <data name="android.software.leanback" xml:space="preserve">
    <value>The app is designed to run on Android TV devices.</value>
  </data>
  <data name="android.software.live_tv" xml:space="preserve">
    <value>The app streams live television programs.</value>
  </data>
  <data name="android.software.live_wallpaper" xml:space="preserve">
    <value>The app uses or provides wallpapers that include animation.</value>
  </data>
  <data name="android.software.managed_users" xml:space="preserve">
    <value>The app supports secondary users and managed profiles.</value>
  </data>
  <data name="android.software.midi" xml:space="preserve">
    <value>The app connects to musical instruments or outputs sound using the Musical Instrument Digital Interface (MIDI) protocol.</value>
  </data>
  <data name="android.software.print" xml:space="preserve">
    <value>The app includes commands for printing documents displayed on the device.</value>
  </data>
  <data name="android.software.securely_removes_users" xml:space="preserve">
    <value>The app can permanently remove users and their associated data.</value>
  </data>
  <data name="android.software.sip" xml:space="preserve">
    <value>The app uses Session Initiation Protocol (SIP) services. By using SIP, the app can support internet telephony operations, such as video conferencing and instant messaging.</value>
  </data>
  <data name="android.software.sip.voip" xml:space="preserve">
    <value>The app uses SIP-based Voice Over Internet Protocol (VoIP) services. By using VoIP, the app can support real-time internet telephony operations, such as two-way video conferencing.

    By using this feature, an app implies that it also uses the android.software.sip feature, unless this parent feature is declared with android:required="false".</value>
  </data>
  <data name="android.software.verified_boot" xml:space="preserve">
    <value>The app includes logic to handle results from the device's verified boot feature, which detects whether the device's configuration changes during a restart operation.</value>
  </data>
  <data name="android.software.webview" xml:space="preserve">
    <value>The app displays content from the internet.</value>
  </data>
</root>